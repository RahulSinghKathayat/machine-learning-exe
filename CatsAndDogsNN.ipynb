{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NITRO V\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cnn.add(Conv2D(32,(3,3),input_shape= (64,64,3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(16,(3,3), activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2))) \n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(64, activation='relu'))\n",
    "cnn.add(Dense(32, activation='relu'))\n",
    "cnn.add(Dense(16, activation='relu'))\n",
    "cnn.add(Dense(8, activation='relu'))\n",
    "cnn.add(Dense(4, activation='relu'))\n",
    "cnn.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NITRO V\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:890: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "def verify_images(directory):\n",
    "    for subdir, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            try:\n",
    "                img = Image.open(file_path)  # Try to open the image\n",
    "                img.verify()  # Verify that it is, in fact, an image\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                print(f\"Removing invalid image file: {file_path}\")\n",
    "                os.remove(file_path)  # Remove invalid image file\n",
    "\n",
    "# Verify images in both training and testing directories\n",
    "verify_images(r\"C:\\Users\\NITRO V\\Downloads\\catsVSdogs\\train data\")\n",
    "verify_images(r\"C:\\Users\\NITRO V\\Downloads\\catsVSdogs\\test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18546 images belonging to 2 classes.\n",
      "Found 6452 images belonging to 2 classes.\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NITRO V\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  35/3000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:44\u001b[0m 76ms/step - loss: 0.6962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NITRO V\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:890: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 578/3000\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:46\u001b[0m 93ms/step - loss: 0.6755"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NITRO V\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 22ms/step - loss: 0.6492 - val_loss: 0.5674\n",
      "Epoch 2/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 17ms/step - loss: 0.5554 - val_loss: 0.5351\n",
      "Epoch 3/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - loss: 0.5117 - val_loss: 0.5314\n",
      "Epoch 4/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.4790 - val_loss: 0.4633\n",
      "Epoch 5/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.4544 - val_loss: 0.4730\n",
      "Epoch 6/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - loss: 0.4365 - val_loss: 0.4540\n",
      "Epoch 7/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.4306 - val_loss: 0.4382\n",
      "Epoch 8/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.4159 - val_loss: 0.4169\n",
      "Epoch 9/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 17ms/step - loss: 0.4070 - val_loss: 0.4789\n",
      "Epoch 10/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - loss: 0.3965 - val_loss: 0.4202\n",
      "Epoch 11/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - loss: 0.3861 - val_loss: 0.4027\n",
      "Epoch 12/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.3809 - val_loss: 0.4034\n",
      "Epoch 13/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 17ms/step - loss: 0.3636 - val_loss: 0.4254\n",
      "Epoch 14/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.3687 - val_loss: 0.3997\n",
      "Epoch 15/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.3559 - val_loss: 0.3989\n",
      "Epoch 16/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.3486 - val_loss: 0.4234\n",
      "Epoch 17/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.3423 - val_loss: 0.4263\n",
      "Epoch 18/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.3280 - val_loss: 0.4279\n",
      "Epoch 19/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.3312 - val_loss: 0.3999\n",
      "Epoch 20/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.3234 - val_loss: 0.4226\n",
      "Epoch 21/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - loss: 0.3174 - val_loss: 0.3803\n",
      "Epoch 22/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.3088 - val_loss: 0.3810\n",
      "Epoch 23/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.3025 - val_loss: 0.4063\n",
      "Epoch 24/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.3002 - val_loss: 0.4008\n",
      "Epoch 25/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - loss: 0.2917 - val_loss: 0.4318\n",
      "Epoch 26/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - loss: 0.2924 - val_loss: 0.4466\n",
      "Epoch 27/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - loss: 0.2818 - val_loss: 0.4443\n",
      "Epoch 28/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.2846 - val_loss: 0.4639\n",
      "Epoch 29/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - loss: 0.2730 - val_loss: 0.4514\n",
      "Epoch 30/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.2731 - val_loss: 0.4769\n",
      "Epoch 31/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.2676 - val_loss: 0.4081\n",
      "Epoch 32/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.2639 - val_loss: 0.4494\n",
      "Epoch 33/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.2633 - val_loss: 0.5062\n",
      "Epoch 34/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - loss: 0.2558 - val_loss: 0.4681\n",
      "Epoch 35/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.2495 - val_loss: 0.4837\n",
      "Epoch 36/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.2463 - val_loss: 0.4641\n",
      "Epoch 37/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.2482 - val_loss: 0.4653\n",
      "Epoch 38/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.2414 - val_loss: 0.4618\n",
      "Epoch 39/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.2356 - val_loss: 0.5191\n",
      "Epoch 40/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.2323 - val_loss: 0.5391\n",
      "Epoch 41/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 17ms/step - loss: 0.2295 - val_loss: 0.5165\n",
      "Epoch 42/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 17ms/step - loss: 0.2242 - val_loss: 0.5393\n",
      "Epoch 43/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6514s\u001b[0m 2s/step - loss: 0.2216 - val_loss: 0.4796\n",
      "Epoch 44/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 14ms/step - loss: 0.2231 - val_loss: 0.5068\n",
      "Epoch 45/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 0.2183 - val_loss: 0.5139\n",
      "Epoch 46/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - loss: 0.2200 - val_loss: 0.4919\n",
      "Epoch 47/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 99ms/step - loss: 0.2108 - val_loss: 0.6742\n",
      "Epoch 48/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 58ms/step - loss: 0.2103 - val_loss: 0.4772\n",
      "Epoch 49/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 29ms/step - loss: 0.2111 - val_loss: 0.5847\n",
      "Epoch 50/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 28ms/step - loss: 0.2052 - val_loss: 0.5215\n",
      "Epoch 51/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 22ms/step - loss: 0.1995 - val_loss: 0.4810\n",
      "Epoch 52/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 21ms/step - loss: 0.1998 - val_loss: 0.5154\n",
      "Epoch 53/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 21ms/step - loss: 0.1931 - val_loss: 0.5439\n",
      "Epoch 54/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 22ms/step - loss: 0.1917 - val_loss: 0.5347\n",
      "Epoch 55/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 21ms/step - loss: 0.1889 - val_loss: 0.5222\n",
      "Epoch 56/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 21ms/step - loss: 0.1902 - val_loss: 0.5114\n",
      "Epoch 57/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 20ms/step - loss: 0.1880 - val_loss: 0.4826\n",
      "Epoch 58/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 69ms/step - loss: 0.1895 - val_loss: 0.4909\n",
      "Epoch 59/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 83ms/step - loss: 0.1886 - val_loss: 0.4702\n",
      "Epoch 60/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 32ms/step - loss: 0.1802 - val_loss: 0.5772\n",
      "Epoch 61/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 29ms/step - loss: 0.1809 - val_loss: 0.4886\n",
      "Epoch 62/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 29ms/step - loss: 0.1740 - val_loss: 0.5447\n",
      "Epoch 63/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 29ms/step - loss: 0.1752 - val_loss: 0.5589\n",
      "Epoch 64/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 29ms/step - loss: 0.1753 - val_loss: 0.5609\n",
      "Epoch 65/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 29ms/step - loss: 0.1713 - val_loss: 0.5682\n",
      "Epoch 66/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 29ms/step - loss: 0.1721 - val_loss: 0.5645\n",
      "Epoch 67/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 29ms/step - loss: 0.1696 - val_loss: 0.5592\n",
      "Epoch 68/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 29ms/step - loss: 0.1643 - val_loss: 0.5355\n",
      "Epoch 69/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 30ms/step - loss: 0.1690 - val_loss: 0.5452\n",
      "Epoch 70/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 30ms/step - loss: 0.1637 - val_loss: 0.5623\n",
      "Epoch 71/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 30ms/step - loss: 0.1603 - val_loss: 0.6404\n",
      "Epoch 72/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 30ms/step - loss: 0.1560 - val_loss: 0.6001\n",
      "Epoch 73/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 30ms/step - loss: 0.1588 - val_loss: 0.5937\n",
      "Epoch 74/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 29ms/step - loss: 0.1574 - val_loss: 0.5711\n",
      "Epoch 75/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 30ms/step - loss: 0.1586 - val_loss: 0.6009\n",
      "Epoch 76/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 29ms/step - loss: 0.1547 - val_loss: 0.5543\n",
      "Epoch 77/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 29ms/step - loss: 0.1526 - val_loss: 0.6312\n",
      "Epoch 78/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 29ms/step - loss: 0.1519 - val_loss: 0.5446\n",
      "Epoch 79/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 30ms/step - loss: 0.1515 - val_loss: 0.5530\n",
      "Epoch 80/80\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 29ms/step - loss: 0.1496 - val_loss: 0.6482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d3d2841bb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r\"C:\\Users\\NITRO V\\Downloads\\catsVSdogs\\train data\",\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        r\"C:\\Users\\NITRO V\\Downloads\\catsVSdogs\\test data\",\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "cnn.fit(train_generator,steps_per_epoch=3000,epochs=80,validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(r\"C:\\Users\\NITRO V\\Downloads\\catsVSdogs\\download.jpg\" ,target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.expand_dims(img,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
     ]
    }
   ],
   "source": [
    "p = cnn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "if p[0][0] < 0.5:\n",
    "    print('cat')\n",
    "else:\n",
    "    print('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
